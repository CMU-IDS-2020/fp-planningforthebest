# Final Project Report

**Project URL**: http://35.194.73.188/

Healthcare patients sometimes need to make critical life decisions in moments where they are cognitively unavailable to do so. This is why the Advance Care Planning (ACP) is created: It is a tool to document ahead of time patient preferences in whether to receive life-sustaining treatments or not in various scenarios. However, the current experience of filling out an ACP is manual and difficult to digest for the patient. The ACP also may not address comprehensive scenarios for whether to receive life-sustaining treatments or not. The goal of our project is to address these limitations, by building a user-friendly survey experience that leverages active learning and generates accurate predictions of patient preferences in different scenarios. We aim to alleviate the stress in filling out an ACP, while helping patients run through as many scenarios as possible with the help of machine learning. 

## Introduction
Modern medicine has made significant progress in prolonging human life. However, there are still times when patients and their families are in a situation where they need to make a decision for receiving life-sustaining treatments (LST) or not. In these urgent and stressful experiences, patients in need of end-of-life (EOL) care may be cognitively unavailable to make an informed decision. To avoid being unprepared to make such an important decision, some people leverage the Advance Care Planning (also known as ACP). The ACP allows people to review their care options consciously ahead of time, and select the care they would like to receive if a fatal event occurs. It is important to note that the ACP does not attempt to be a decision-making tool. Rather, it is an opportunity for the patient to proactively plan for the worst case scenario. In the best case scenario right now, ACPs can represent a patient’s wishes in the time of need, in the form of a written description for family and medical professionals. 

While the ACP works well in theory, in practice there are significant challenges. For the patient, the process of filling in the ACP is very manual and difficult to digest. Second, ACPs may not address every possible EOL care scenario, and therefore lead the patient to go through an unpreferred outcome.

Our motivation in this project is to minimize the consequences of insufficient care planning, by providing a solution for the patient. Our solution will be a user-friendly survey experience that anticipates comprehensive scenarios relevant to the patient. There is an opportunity to use active learning (machine learning) to determine the unique lists of questions to survey the patients to better elicit the patients’ EoL decision preferences. The proposed model could alleviate a lot of the laborious answer collection process from patients and also show them information along the way of how their answers will inform their eventual decision. The model will also predict preferences to additional scenarios based on the patient’s past responses, to help the ACP documentation be even more comprehensive.

## Related Work
We studied prior applications that explore machine’s role in supporting human decision-making, and experiments that used random forest as a basis for active learning. The Moral Machine looks at challenges encountered in the process of setting ethical principles that should guide the development of artificial intelligence (Awad, Dsouza, Kim, Schulz, Henrich, Shariff, Bonnefon, Rahwan, 2018). In addition to the complexities that exist in teaching machines how to behave within societal-level expectations of ethics, it is also difficult to represent individual preferences and values (McElfresh, Dooley, Cui, Griesman, Wang, Will, Sehgal, Dickerson, 2020). To evaluate the most suitable machine learning methods to advance the current ACP process, we reviewed prior applications of active learning algorithms built on logistic regression (Yang and Loog, 2018).

## Methods

## Results

## Discussion
The initial goal for this application is to encourage patients to plan ahead on critical life decisions. We set out to ease their anxiety by developing a solution that simplifies the documentation process, minimize ambiguity around patient intent, and present informed guidance for proxy decision makers. In many ACP products in the market, patients need to have multiple conversations and repetitively enforce their intentions across different stakeholders— medical professionals, patients’ family members, and lawyers, to name a few. From a functional perspective, our web application efficiently enables patients to accurately document their intent in a straightforward manner, especially given complicated health circumstances. 

On the other hand, from an ethical perspective patients may question whether their documented preferences are accurately representing their needs or influenced by the machine’s predicted responses. Initially, we knew we wanted to make informed deployment choices that support patients’ decision-making process, rather than attempt to dictate decisions for patients. However, while creating the application there were a few occasions where it was challenging to decide whether certain interface and algorithm designs are unintentionally influencing patients’ decision-making. In the initial 25 questions posed for patients to train our model, we debated whether we should allow patients to skip question(s). If the patient skips questions, our model risks training on insufficient amounts of data and can overfit. Therefore we currently don’t offer the option to skip, but this means that patients may not be absolutely certain about each response they put forth.

Additionally, in an effort to simplify the prompts in which patients respond to, our model uses transitivity properties to interpret patient preferences. While from a user experience perspective it saves the patient a lot of time in processing answers, this may mean that the machine is not very sensitive in interpreting patient preferences. Patient conditions and needs are hard to generalize, and while transitivity could account for many observations, there may still be edge case preferences that are hard to predict for. These considerations make it challenging to assess the model’s accuracy in recording patient preferences. 

## Future Work
**Build interactions to help patients better understand the model**
Gaining patient trust is an essential part of this project, and we find that there are opportunities to explore visualizations to help patients better understand how the model works. Currently, we have a feature importance bar chart that dynamically changes based on patient input. However, for our next step we might try to leverage partial dependence to better illustrate potential outcomes of the model, depending on feature importance. For example, we could create 10 interactive levers, each representing a feature. Patients can adjust the importance of each feature, and view how that might alter the model prediction. This creates greater transparency for how the model is interpreting patient inputs, thus offering us a chance to better assess the model accuracy. From the application developer standpoint, if the model is significantly biased towards one feature, we would be able to quickly take note of that from having plotted the partial dependence.  

**Help patients plan for diverse circumstances**
Currently there are only 10 features used by the model and are shown to patients. In order to document an even more comprehensive understanding of patient decisions in diverse circumstances, we would want to add more features. The more features we add, the better we can help patients plan for any scenario they may find themselves in. 

**Improve model accuracy by training with more prior data** 
To reduce the risks of overfitting, we can train the model with more prior patient data. The model is currently only trained with data we collected from students in the Interactive Data Science class. More data can help increase accuracy of the model.

**Leverage collaborative filtering**
Once we have more data, we can also use collaborative filtering to better predict user intents of patients with similar circumstances. We can determine similarity between patients by considering their explicit responses to each survey question. However, with this approach we will still have the challenge of determining where a predicted intent would lean towards (and by how much) between two opposite decisions: reject life support or accept life support.
